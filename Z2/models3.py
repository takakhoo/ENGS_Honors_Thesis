#!/usr/bin/env python3
"""
models.py  –  Dual‑Resolution FiLM‑conditioned Deep‑UNet with CBAM
##################################################################
High‑detail spectrogram restoration network for 22 050 Hz / 80‑mel
input and HiFi‑GAN output.

Key ideas
---------
1. *Dual‑Resolution UNet* – an HR path keeps 80‑mel fidelity; an LR
   path (40‑mel) captures broader context cheaply.
2. *CBAM* channel+spatial attention after every residual stack.
3. *FiLM conditioning* (γ, β) generated by a bi‑LSTM that also
   predicts the 10 inverse‑correction parameters.
4. *Explicit inverse correction* (gain, EQ, echo, reverb) still in
   place – now FiLM‑modulated so the network can soften or amplify
   physics‑based priors.

"""

from typing import List, Tuple
import torch
import torch.nn as nn
import torch.nn.functional as F

# ──────────────────────────────── Utilities ─────────────────────────────── #

class CBAM(nn.Module):
    """Convolutional Block Attention Module (channel + spatial)."""
    def __init__(self, ch: int, reduction: int = 16):
        super().__init__()
        mid = max(ch // reduction, 4)
        # Channel‑attention MLP
        self.mlp = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(ch, mid, 1, bias=False), nn.LeakyReLU(negative_slope=0.1, inplace=False),
            nn.Conv2d(mid, ch, 1, bias=False)
        )
        # Spatial‑attention conv
        self.conv_spatial = nn.Conv2d(2, 1, 7, padding=3, bias=False)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Channel attention
        ca = torch.sigmoid(self.mlp(x))
        x = x * ca
        # Spatial attention
        avg = torch.mean(x, dim=1, keepdim=True)
        mx, _ = torch.max(x,  dim=1, keepdim=True)
        sa = torch.sigmoid(self.conv_spatial(torch.cat([avg, mx], dim=1)))
        return x * sa


class ResidualStack(nn.Module):
    """
    A small residual stack (Conv‑BN‑ReLU)×N  +  CBAM.
    Works for arbitrary `in_ch → out_ch`.
    """
    def __init__(self,
                 in_ch:     int,
                 out_ch:    int,
                 stride:    int  = 1,
                 n_blocks:  int  = 2,
                 dilate:    bool = False):
        super().__init__()
        layers: List[nn.Module] = []
        for i in range(n_blocks):
            d = 2 ** i if dilate else 1          # growing dilation if wanted
            layers += [
                nn.Conv2d(in_ch if i == 0 else out_ch,
                          out_ch,
                          kernel_size=3,
                          stride=stride if i == 0 else 1,
                          padding=d,
                          dilation=d,
                          bias=False),
                nn.BatchNorm2d(out_ch),
                nn.LeakyReLU(negative_slope=0.1, inplace=False)
            ]
        self.body = nn.Sequential(*layers)
        self.cbam = CBAM(out_ch)
        self.skip = nn.Identity() if (in_ch == out_ch and stride == 1) else \
            nn.Conv2d(in_ch, out_ch, 1, stride, bias=False)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        y = self.body(x) + self.skip(x)
        return self.cbam(y)


class FiLM(nn.Module):
    """Applies FiLM scale γ and shift β (per‑channel)."""
    def __init__(self, n_ch: int):
        super().__init__()
        self.n_ch = n_ch
    def forward(self,
                feat: torch.Tensor,   # [B,C,H,W]
                gam:  torch.Tensor,   # [B,C]
                bet:  torch.Tensor) -> torch.Tensor:  # [B,C]
        gam = gam.view(gam.size(0), self.n_ch, 1, 1)
        bet = bet.view(bet.size(0), self.n_ch, 1, 1)
        return feat * gam + bet


# ────────────────────── Dual‑Resolution UNet Backbone ───────────────────── #

class DualUNet(nn.Module):
    """
    High–resolution 80‑mel and low–resolution 40‑mel encoders whose features
    are fused in a FiLM‑conditioned decoder.  FiLM γ/β come in as *scalars*
    per frame; we expand them to full channel vectors on the fly.
    """

    def __init__(self, base: int = 64, blocks: int = 2):
        super().__init__()
        self.base = base

        # ── HR encoder ──
        self.h1 = ResidualStack(1,      base,     1, blocks)
        self.h2 = ResidualStack(base,   base*2,   2, blocks)
        self.h3 = ResidualStack(base*2, base*4,   2, blocks)
        self.h4 = ResidualStack(base*4, base*8,   2, blocks)

        # ── LR encoder (freq‑pool ×2) ──
        self.pool_lr = nn.AvgPool2d((2, 1))
        self.l1 = ResidualStack(1,      base,     1, blocks)
        self.l2 = ResidualStack(base,   base*2,   2, blocks)
        self.l3 = ResidualStack(base*2, base*4,   2, blocks)
        self.l4 = ResidualStack(base*4, base*8,   2, blocks, dilate=True)

        # ── Decoder ──
        self.up4 = nn.ConvTranspose2d(base*16, base*8, 2, 2)
        self.d4  = ResidualStack(base*8 + base*4, base*8, 1, blocks)
        self.up3 = nn.ConvTranspose2d(base*8,  base*4, 2, 2)
        self.d3  = ResidualStack(base*4 + base*2, base*4, 1, blocks)
        self.up2 = nn.ConvTranspose2d(base*4,  base*2, 2, 2)
        self.d2  = ResidualStack(base*2 + base,   base*2, 1, blocks)
        self.up1 = nn.ConvTranspose2d(base*2,  base,   2, 2)
        self.d1  = ResidualStack(base + 1,        base,   1, blocks)
        self.out = nn.Conv2d(base, 1, 1)

        # FiLM (γ,β) per level
        self.film4 = FiLM(base*8)
        self.film3 = FiLM(base*4)
        self.film2 = FiLM(base*2)
        self.film1 = FiLM(base)

    # ------------------------------------------------------------------ #
    
        # ------------------------------------------------------------------ #
    def forward(self,
                x: torch.Tensor,
                gammas, betas) -> torch.Tensor:
        """
        gammas / betas come in reversed (lvl4→lvl1).
        """

        # ---------- helper ---------- #
        def _align(ref: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
            """Resize t to ref's H×W with bilinear interpolation."""
            if ref.shape[-2:] != t.shape[-2:]:
                t = F.interpolate(t, size=ref.shape[-2:],
                                  mode='bilinear', align_corners=False)
            return t

        def _expand(scalar: torch.Tensor, C: int) -> torch.Tensor:
            scalar = scalar.mean(dim=1, keepdim=True)   # [B,1]
            return scalar.expand(-1, C)                 # [B,C]
        # ---------------------------- #

        # ── HR encoder ──
        h1 = self.h1(x)
        h2 = self.h2(h1)
        h3 = self.h3(h2)
        h4 = self.h4(h3)

        # ── LR encoder ──
        xl = self.pool_lr(x)           # [B,1,40,T]
        l1 = self.l1(xl)
        l2 = self.l2(l1)
        l3 = self.l3(l2)
        l4 = self.l4(l3)

        # ── deepest fusion (make sure l4 matches h4) ──
        z = torch.cat([h4, _align(h4, l4)], dim=1)   # 16·base ch

        # ── decoder Lv‑4 ──
        z = self.up4(z)
        z = self.d4(torch.cat([z, _align(z, h3)], dim=1))
        z = self.film4(z, _expand(gammas[0], self.base*8),
                          _expand(betas[0],  self.base*8))

        # ── decoder Lv‑3 ──
        z = self.up3(z)
        z = self.d3(torch.cat([z, _align(z, h2)], dim=1))
        z = self.film3(z, _expand(gammas[1], self.base*4),
                          _expand(betas[1],  self.base*4))

        # ── decoder Lv‑2 ──
        z = self.up2(z)
        z = self.d2(torch.cat([z, _align(z, h1)], dim=1))
        z = self.film2(z, _expand(gammas[2], self.base*2),
                          _expand(betas[2],  self.base*2))

        # ── decoder Lv‑1 ──
        z = self.up1(z)
        z = _align(x, z)                    # final spatial match to input
        z = self.d1(torch.cat([z, x], dim=1))
        z = self.film1(z, _expand(gammas[3], self.base),
                          _expand(betas[3],  self.base))

        return torch.clamp(self.out(z) + x, 0.0, 1.0)





# ─────────────────────  LSTM → FiLM + Param branch  ─────────────────── #

class ParamLSTM(nn.Module):
    """
    Two‑layer bi‑directional LSTM.
    Output per frame:  γ/β for 4 levels  +  10 control params.
    """
    def __init__(self, hidden: int = 64, n_levels: int = 4, n_params: int = 10):
        super().__init__()
        self.bilstm = nn.LSTM(1, hidden, 2, batch_first=True, bidirectional=True)
        self.proj   = nn.Linear(hidden * 2, n_levels * 2 + n_params)

    def forward(self, energy: torch.Tensor) -> Tuple[List[torch.Tensor],
                                                     List[torch.Tensor],
                                                     torch.Tensor]:
        """
        Parameters
        ----------
        energy : [B,T,1]   mean energy per frame.

        Returns
        -------
        gammas : list of 4 tensors [B,C]   (C differs per decoder level)
        betas  : list of 4 tensors [B,C]
        params : [B,T,10]  control parameters (sigmoid‑normalised)
        """
        seq, _ = self.bilstm(energy)         # [B,T,H*2]
        y = torch.sigmoid(self.proj(seq))    # [B,T, 4*2+10 = 18]
        # Split
        gammas = [y[...,  i] for i in range(4)]       # each [B,T]
        betas  = [y[..., i+4] for i in range(4)]
        params = y[..., 8:]                           # [B,T,10]
        return gammas, betas, params


# ─────────────────────────  Inverse correction  ─────────────────────── #

def inverse_correction(x: torch.Tensor,
                       p_norm: torch.Tensor,
                       sr: int,
                       hop: int) -> torch.Tensor:
    """
    Same physics‑based masks as before, but using **frame‑wise** parameters.

    x      : [B,1,80,T]   (0–1 normalised)
    p_norm : [B,T,10]     (0–1 each)
    """
    eps = 1e-6
    B, _, F, T = x.shape
    
    # Debug: Print input ranges
    if torch.rand(1).item() < 0.05:  # Only print 5% of the time
        print(f"[DEBUG] Input x range: {x.min().item():.3f} to {x.max().item():.3f}")
    
    # Un‑normalise
    gain_db      = p_norm[..., 0] * 2.0  - 1.0
    eq_fc        = p_norm[..., 1] * (sr / 2.0)
    eq_Q         = p_norm[..., 2] * 9.9  + 0.1
    eq_gain_db   = p_norm[..., 3] * 20.0 - 10.0
    rev_decay    = p_norm[..., 7] * 9.9  + 0.1
    echo_delay   = p_norm[..., 8] * 1000.0  # ms (changed from 100.0 to 1000.0 to handle larger delays)
    echo_atten   = p_norm[..., 9] * 0.5 + 0.3  # Map [0,1] to [0.3,0.8] to better match parameter files

    # Debug: Print parameter ranges and statistics
    if torch.rand(1).item() < 0.05:
        print(f"[DEBUG] Echo params - delay: {echo_delay.mean().item():.1f}ms "
              f"(min: {echo_delay.min().item():.1f}, max: {echo_delay.max().item():.1f}), "
              f"atten: {echo_atten.mean().item():.3f} "
              f"(min: {echo_atten.min().item():.3f}, max: {echo_atten.max().item():.3f})")

    # Gain mask
    inv_gain = 1.0 / (1.0 + gain_db + eps)        # [B,T]
    inv_gain = inv_gain.view(B, 1, 1, T)

    # EQ Gaussian mask
    freqs = torch.linspace(0.0, sr / 2.0, steps=F,
                           device=x.device).view(1, 1, F, 1)
    fc  = eq_fc.unsqueeze(1).unsqueeze(2)
    Q   = eq_Q.unsqueeze(1).unsqueeze(2)
    gdb = eq_gain_db.unsqueeze(1).unsqueeze(2)
    bw  = fc / (Q + eps)
    inv_eq = 1.0 / (1.0 + gdb *
                    torch.exp(-((freqs - fc) ** 2) /
                              (2.0 * (bw ** 2) + eps)))
    mask = inv_gain * inv_eq                               # [B,1,F,T]

    # Echo subtraction (use average per‑sample to keep it cheap)
    # Convert delay from ms to frames, ensuring it's within valid range
    max_delay_frames = T // 2  # Don't allow delays longer than half the signal
    d_frames = ((echo_delay * sr) / (1000.0 * hop)).float()  # Convert to float first
    d_frames = torch.mean(d_frames, dim=1)  # Average over time to get [B]
    d_frames = torch.clamp(d_frames, min=1, max=max_delay_frames).long()  # Convert to long after clamping
    
    a_frames = torch.mean(echo_atten, dim=1)  # [B]
    x_corr = x.clone()
    
    # Create a new tensor for echo correction instead of modifying in-place
    echo_correction = torch.zeros_like(x_corr)
    for b in range(B):
        d = d_frames[b].item()
        if 1 <= d < T:
            echo_correction[b, ..., d:] = a_frames[b] * x_corr[b, ..., :-d]
    
    # Debug: Print detailed echo correction info
    if torch.rand(1).item() < 0.05:
        print(f"[DEBUG] Echo correction - delay frames: {d_frames.tolist()}, "
              f"attenuation: {a_frames.tolist()}")
        print(f"[DEBUG] Echo correction range: {echo_correction.min().item():.3f} to "
              f"{echo_correction.max().item():.3f}")
        if echo_correction.max().item() == 0:
            print(f"[DEBUG] Zero correction possible reasons:")
            print(f"  - Delay frames: {d_frames.tolist()}")
            print(f"  - Attenuation values: {a_frames.tolist()}")
            if d_frames[0] < T:  # Only try to print input range if delay is valid
                delayed_signal = x_corr[..., :-d_frames[0].item()]
                if delayed_signal.numel() > 0:  # Only try to get min/max if tensor is not empty
                    print(f"  - Input signal range at delay points: "
                          f"{delayed_signal.min().item():.3f} to "
                          f"{delayed_signal.max().item():.3f}")
    
    x_corr = x_corr - echo_correction
    x_corr = torch.clamp(x_corr, 0.0, 1.0)  # Clamp after echo correction

    # Debug: Print corrected signal ranges
    if torch.rand(1).item() < 0.05:
        print(f"[DEBUG] Corrected x range: {x_corr.min().item():.3f} to "
              f"{x_corr.max().item():.3f}")

    # Reverb scalar
    r = 1.0 / (1.0 + torch.mean(rev_decay, 1) + eps)     # [B]
    x_corr = x_corr * r.view(B, 1, 1, 1)
    x_corr = torch.clamp(x_corr, 0.0, 1.0)  # Clamp after reverb

    # Final debug: Print output ranges
    if torch.rand(1).item() < 0.05:
        print(f"[DEBUG] Final output range: {x_corr.min().item():.3f} to "
              f"{x_corr.max().item():.3f}")

    return x_corr * mask


# ───────────────────────────── Full network ──────────────────────────── #

class MasterNet(nn.Module):
    def __init__(self, sr: int = 22_050, hop: int = 256):
        super().__init__()
        self.sr, self.hop = sr, hop
        self.backbone = DualUNet()
        self.control  = ParamLSTM()

    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        x : [B,1,80,T]  (0–1)
        Returns
        -------
        restored_spec : [B,1,80,T]  (0–1)
        params_norm   : [B,T,10]    each 0–1
        """
        # Mean energy curve → LSTM
        energy = x.mean(dim=2).permute(0, 2, 1)         # [B,T,1]
        gammas, betas, params = self.control(energy)    # 4×γ, 4×β, 10 params

        # Backbone UNet with FiLM
        restored = self.backbone(x, gammas[::-1], betas[::-1])

        # Physics‑based inverse
        inverse  = inverse_correction(x, params, self.sr, self.hop)

        out = torch.clamp(restored + inverse, 0.0, 1.0)

        # Occasional debug print
        if torch.rand(1).item() < 0.05:
            print(f"[DEBUG] out range {out.min().item():.3f} … {out.max().item():.3f}")

        return out, params


# ──────────────────────────── Self‑test ******************************** #

def _selftest(batch: int = 2, frames: int = 512):
    print("[SELFTEST] Running forward pass …")
    x = torch.rand(batch, 1, 80, frames)                 # fake 0–1 spectrograms
    net = MasterNet()                                    # CPU by default
    with torch.no_grad():
        y, p = net(x)
    print("[SELFTEST] out", y.shape, "params", p.shape,
          "min/max", y.min().item(), y.max().item())
    assert y.shape == x.shape
    assert p.shape == (batch, frames, 10)
    print("[SELFTEST] ✅  shapes OK")

if __name__ == "__main__":
    _selftest()
